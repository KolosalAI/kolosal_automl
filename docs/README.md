# ğŸ“š Kolosal AutoML Documentation

Welcome to the comprehensive documentation for **Kolosal AutoML** â€” a high-performance automated machine learning framework written in pure Rust.

## ğŸ¯ Quick Navigation

### ğŸ‘‹ New to Kolosal AutoML?
- [ğŸ“– **Getting Started**](getting-started/) â€” Installation, setup, and first steps
- [ğŸ“ **User Guides**](user-guides/) â€” Step-by-step tutorials for common tasks
- [ğŸ’» **Web Interface Guide**](user-guides/web-interface.md) â€” Using the built-in web UI

### ğŸš€ Deploy to Production
- [ğŸ³ **Docker Deployment**](deployment/docker.md) â€” Containerized deployment

### ğŸ”§ API Integration
- [ğŸ“‹ **API Reference**](api-reference/) â€” Complete REST API documentation

### ğŸ‘©â€ğŸ’» Development
- [ğŸ› ï¸ **Development Setup**](development/) â€” Developer environment and contributing

### ğŸ“¦ Module Documentation
- [ğŸ§© **Module Docs**](modules/) â€” Detailed API docs for each module

---

## ğŸš€ What is Kolosal AutoML?

Kolosal AutoML is a comprehensive, production-ready machine learning platform written in pure Rust that provides:

- **Automated model training** with 8+ algorithm families
- **Hyperparameter optimization** (Bayesian, TPE, ASHT)
- **Data preprocessing** with adaptive strategy selection
- **High-performance inference** with batch processing and caching
- **Web server** with REST API and interactive UI
- **CLI** for scripting and automation

## Quick Start

### Installation
```bash
# Clone the repository
git clone https://github.com/KolosalAI/kolosal_automl.git
cd kolosal_automl

# Build
cargo build --release
```

### Basic Usage

#### Command Line Interface
```bash
# Interactive mode
cargo run --release

# Train a model
cargo run --release -- train --data data.csv --target label --model random_forest

# Start web server
cargo run --release -- serve --port 8080

# Dataset info
cargo run --release -- info --data data.csv

# Benchmark models
cargo run --release -- benchmark --data data.csv --target label
```

#### Rust API
```rust
use kolosal_automl::prelude::*;
use polars::prelude::*;

// Load data
let df = CsvReadOptions::default()
    .try_into_reader_with_file_path(Some("data.csv".into()))?
    .finish()?;

// Configure and train
let config = TrainingConfig::new(TaskType::Regression, "target")
    .with_model(ModelType::RandomForest)
    .with_n_estimators(100)
    .with_max_depth(10);

let mut engine = TrainEngine::new(config);
engine.fit(&df)?;

// Predict
let predictions = engine.predict(&df)?;
```

## Architecture Overview

```
kolosal-automl/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib.rs                  # Library root with prelude
â”‚   â”œâ”€â”€ main.rs                 # CLI entry point
â”‚   â”œâ”€â”€ error.rs                # Error types
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/          # Data scaling, encoding, imputation
â”‚   â”œâ”€â”€ training/               # Model training (8+ algorithms)
â”‚   â”œâ”€â”€ inference/              # High-performance inference
â”‚   â”œâ”€â”€ optimizer/              # Hyperparameter optimization
â”‚   â”‚
â”‚   â”œâ”€â”€ explainability/         # Feature importance, PDP
â”‚   â”œâ”€â”€ ensemble/               # Voting, stacking, blending
â”‚   â”œâ”€â”€ calibration/            # Probability calibration
â”‚   â”œâ”€â”€ anomaly/                # Isolation Forest, LOF
â”‚   â”œâ”€â”€ drift/                  # Data & concept drift detection
â”‚   â”‚
â”‚   â”œâ”€â”€ feature_engineering/    # Polynomial, interactions, TF-IDF
â”‚   â”œâ”€â”€ imputation/             # MICE, KNN, iterative
â”‚   â”œâ”€â”€ synthetic/              # SMOTE, ADASYN
â”‚   â”œâ”€â”€ timeseries/             # Time series features & CV
â”‚   â”‚
â”‚   â”œâ”€â”€ batch/                  # Priority-based batch processing
â”‚   â”œâ”€â”€ cache/                  # Multi-level LRU+TTL caching
â”‚   â”œâ”€â”€ memory/                 # Memory pooling & monitoring
â”‚   â”œâ”€â”€ streaming/              # Backpressure-controlled streaming
â”‚   â”œâ”€â”€ quantization/           # INT8/FP16 quantization
â”‚   â”œâ”€â”€ monitoring/             # Latency, throughput, alerts
â”‚   â”œâ”€â”€ tracking/               # Experiment tracking
â”‚   â”‚
â”‚   â”œâ”€â”€ device/                 # Hardware detection & auto-config
â”‚   â”œâ”€â”€ adaptive/               # Adaptive preprocessing & hyperopt
â”‚   â”œâ”€â”€ precision/              # Mixed precision (FP16/BF16)
â”‚   â”œâ”€â”€ security/               # Auth, rate limiting, TLS
â”‚   â”‚
â”‚   â”œâ”€â”€ nas/                    # Neural architecture search (DARTS)
â”‚   â”œâ”€â”€ autopipeline/           # Automatic pipeline construction
â”‚   â”œâ”€â”€ architectures/          # TabNet, FT-Transformer
â”‚   â”œâ”€â”€ export/                 # ONNX, PMML serialization
â”‚   â”œâ”€â”€ utils/                  # SIMD, parallel, metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ server/                 # Axum HTTP server + REST API
â”‚   â””â”€â”€ cli/                    # CLI with clap
â”‚
â”œâ”€â”€ examples/                   # Usage examples
â”œâ”€â”€ tests/                      # Integration tests
â”œâ”€â”€ benches/                    # Benchmarks (criterion)
â”œâ”€â”€ kolosal-web/                # Web UI (htmx + Alpine.js)
â””â”€â”€ docs/                       # Documentation
```

## Development

```bash
# Run tests
cargo test

# Run benchmarks
cargo bench

# Build release
cargo build --release

# Generate API docs
cargo doc --open
```

## Version Information

**Current Version:** v0.5.0

See [CHANGELOG.md](../CHANGELOG.md) for release history.

## License

MIT License â€” see [LICENSE](../LICENSE) for details.
