//! Stacking ensemble method

use crate::error::{KolosalError, Result};
use crate::training::Model;
use crate::training::cross_validation::{CrossValidator, CVStrategy};
use ndarray::{Array1, Array2};
use serde::{Deserialize, Serialize};

/// Configuration for stacking ensemble
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StackingConfig {
    /// Number of cross-validation folds
    pub n_folds: usize,
    /// Whether to use probabilities (for classification)
    pub use_probabilities: bool,
    /// Whether to include original features in meta-learner input
    pub passthrough: bool,
    /// Random seed
    pub seed: Option<u64>,
}

impl Default for StackingConfig {
    fn default() -> Self {
        Self {
            n_folds: 5,
            use_probabilities: false,
            passthrough: false,
            seed: None,
        }
    }
}

/// Stacking classifier
pub struct StackingClassifier<F>
where
    F: Fn(&Array2<f64>, &Array1<f64>) -> Result<Box<dyn Model>>,
{
    /// Configuration
    config: StackingConfig,
    /// Base model factory functions
    base_model_factories: Vec<F>,
    /// Fitted base models (one per fold per base learner)
    fitted_base_models: Option<Vec<Vec<Box<dyn Model>>>>,
    /// Meta-learner factory
    meta_learner_factory: Option<F>,
    /// Fitted meta-learner
    fitted_meta_learner: Option<Box<dyn Model>>,
}

impl<F> StackingClassifier<F>
where
    F: Fn(&Array2<f64>, &Array1<f64>) -> Result<Box<dyn Model>>,
{
    /// Create a new stacking classifier
    pub fn new(config: StackingConfig) -> Self {
        Self {
            config,
            base_model_factories: Vec::new(),
            fitted_base_models: None,
            meta_learner_factory: None,
            fitted_meta_learner: None,
        }
    }

    /// Add a base model
    pub fn add_base_model(mut self, factory: F) -> Self {
        self.base_model_factories.push(factory);
        self
    }

    /// Set the meta-learner
    pub fn with_meta_learner(mut self, factory: F) -> Self {
        self.meta_learner_factory = Some(factory);
        self
    }

    /// Fit the stacking ensemble
    pub fn fit(&mut self, x: &Array2<f64>, y: &Array1<f64>) -> Result<()> {
        if self.base_model_factories.is_empty() {
            return Err(KolosalError::ValidationError(
                "No base models provided".to_string(),
            ));
        }

        if self.meta_learner_factory.is_none() {
            return Err(KolosalError::ValidationError(
                "No meta-learner provided".to_string(),
            ));
        }

        let n_samples = x.nrows();
        let n_base_models = self.base_model_factories.len();
        let n_folds = self.config.n_folds;

        // Create cross-validator
        let cv = CrossValidator::new(CVStrategy::KFold {
            n_splits: n_folds,
            shuffle: true,
        })
        .with_random_state(self.config.seed.unwrap_or(42));

        let splits = cv.split(n_samples, None, None)?;

        // Initialize meta-features matrix
        let meta_features_cols = if self.config.passthrough {
            n_base_models + x.ncols()
        } else {
            n_base_models
        };
        let mut meta_features = Array2::zeros((n_samples, meta_features_cols));
        let mut fitted_models: Vec<Vec<Box<dyn Model>>> = (0..n_base_models).map(|_| Vec::new()).collect();

        // Generate out-of-fold predictions for each base model
        for (base_idx, factory) in self.base_model_factories.iter().enumerate() {
            for split in &splits {
                // Train on training fold
                let x_train = split.train_indices.iter().map(|&i| x.row(i).to_owned()).collect::<Vec<_>>();
                let y_train: Vec<f64> = split.train_indices.iter().map(|&i| y[i]).collect();
                
                let x_train = Array2::from_shape_vec(
                    (x_train.len(), x.ncols()),
                    x_train.into_iter().flat_map(|r| r.to_vec()).collect(),
                )?;
                let y_train = Array1::from_vec(y_train);

                let model = factory(&x_train, &y_train)?;

                // Predict on validation fold
                let x_val: Vec<_> = split.test_indices.iter().map(|&i| x.row(i).to_owned()).collect();
                let x_val = Array2::from_shape_vec(
                    (x_val.len(), x.ncols()),
                    x_val.into_iter().flat_map(|r| r.to_vec()).collect(),
                )?;

                let predictions = model.predict(&x_val)?;

                // Store predictions as meta-features
                for (local_idx, &global_idx) in split.test_indices.iter().enumerate() {
                    meta_features[[global_idx, base_idx]] = predictions[local_idx];
                }

                fitted_models[base_idx].push(model);
            }
        }

        // Add passthrough features if configured
        if self.config.passthrough {
            for i in 0..n_samples {
                for j in 0..x.ncols() {
                    meta_features[[i, n_base_models + j]] = x[[i, j]];
                }
            }
        }

        // Fit meta-learner on meta-features
        let meta_factory = self.meta_learner_factory.as_ref().unwrap();
        let meta_learner = meta_factory(&meta_features, y)?;

        self.fitted_base_models = Some(fitted_models);
        self.fitted_meta_learner = Some(meta_learner);

        Ok(())
    }

    /// Make predictions
    pub fn predict(&self, x: &Array2<f64>) -> Result<Array1<f64>> {
        let fitted_models = self.fitted_base_models.as_ref().ok_or_else(|| {
            KolosalError::ValidationError("Model not fitted".to_string())
        })?;

        let meta_learner = self.fitted_meta_learner.as_ref().ok_or_else(|| {
            KolosalError::ValidationError("Model not fitted".to_string())
        })?;

        let n_samples = x.nrows();
        let n_base_models = fitted_models.len();

        // Get predictions from each base model (average across folds)
        let meta_features_cols = if self.config.passthrough {
            n_base_models + x.ncols()
        } else {
            n_base_models
        };
        let mut meta_features = Array2::zeros((n_samples, meta_features_cols));

        for (base_idx, fold_models) in fitted_models.iter().enumerate() {
            // Average predictions across fold models
            let mut sum_preds = Array1::zeros(n_samples);
            
            for model in fold_models {
                let preds = model.predict(x)?;
                sum_preds = sum_preds + preds;
            }

            let avg_preds = sum_preds / fold_models.len() as f64;

            for i in 0..n_samples {
                meta_features[[i, base_idx]] = avg_preds[i];
            }
        }

        // Add passthrough features
        if self.config.passthrough {
            for i in 0..n_samples {
                for j in 0..x.ncols() {
                    meta_features[[i, n_base_models + j]] = x[[i, j]];
                }
            }
        }

        meta_learner.predict(&meta_features)
    }
}

/// Stacking regressor
pub struct StackingRegressor<F>
where
    F: Fn(&Array2<f64>, &Array1<f64>) -> Result<Box<dyn Model>>,
{
    /// Configuration
    config: StackingConfig,
    /// Base model factory functions
    base_model_factories: Vec<F>,
    /// Fitted base models
    fitted_base_models: Option<Vec<Vec<Box<dyn Model>>>>,
    /// Meta-learner factory
    meta_learner_factory: Option<F>,
    /// Fitted meta-learner
    fitted_meta_learner: Option<Box<dyn Model>>,
}

impl<F> StackingRegressor<F>
where
    F: Fn(&Array2<f64>, &Array1<f64>) -> Result<Box<dyn Model>>,
{
    /// Create a new stacking regressor
    pub fn new(config: StackingConfig) -> Self {
        Self {
            config,
            base_model_factories: Vec::new(),
            fitted_base_models: None,
            meta_learner_factory: None,
            fitted_meta_learner: None,
        }
    }

    /// Add a base model
    pub fn add_base_model(mut self, factory: F) -> Self {
        self.base_model_factories.push(factory);
        self
    }

    /// Set the meta-learner
    pub fn with_meta_learner(mut self, factory: F) -> Self {
        self.meta_learner_factory = Some(factory);
        self
    }

    /// Fit the stacking ensemble
    pub fn fit(&mut self, x: &Array2<f64>, y: &Array1<f64>) -> Result<()> {
        if self.base_model_factories.is_empty() {
            return Err(KolosalError::ValidationError(
                "No base models provided".to_string(),
            ));
        }

        if self.meta_learner_factory.is_none() {
            return Err(KolosalError::ValidationError(
                "No meta-learner provided".to_string(),
            ));
        }

        let n_samples = x.nrows();
        let n_base_models = self.base_model_factories.len();
        let n_folds = self.config.n_folds;

        let cv = CrossValidator::new(CVStrategy::KFold {
            n_splits: n_folds,
            shuffle: true,
        })
        .with_random_state(self.config.seed.unwrap_or(42));

        let splits = cv.split(n_samples, None, None)?;

        let meta_features_cols = if self.config.passthrough {
            n_base_models + x.ncols()
        } else {
            n_base_models
        };
        let mut meta_features = Array2::zeros((n_samples, meta_features_cols));
        let mut fitted_models: Vec<Vec<Box<dyn Model>>> = (0..n_base_models).map(|_| Vec::new()).collect();

        for (base_idx, factory) in self.base_model_factories.iter().enumerate() {
            for split in &splits {
                let x_train = split.train_indices.iter().map(|&i| x.row(i).to_owned()).collect::<Vec<_>>();
                let y_train: Vec<f64> = split.train_indices.iter().map(|&i| y[i]).collect();
                
                let x_train = Array2::from_shape_vec(
                    (x_train.len(), x.ncols()),
                    x_train.into_iter().flat_map(|r| r.to_vec()).collect(),
                )?;
                let y_train = Array1::from_vec(y_train);

                let model = factory(&x_train, &y_train)?;

                let x_val: Vec<_> = split.test_indices.iter().map(|&i| x.row(i).to_owned()).collect();
                let x_val = Array2::from_shape_vec(
                    (x_val.len(), x.ncols()),
                    x_val.into_iter().flat_map(|r| r.to_vec()).collect(),
                )?;

                let predictions = model.predict(&x_val)?;

                for (local_idx, &global_idx) in split.test_indices.iter().enumerate() {
                    meta_features[[global_idx, base_idx]] = predictions[local_idx];
                }

                fitted_models[base_idx].push(model);
            }
        }

        if self.config.passthrough {
            for i in 0..n_samples {
                for j in 0..x.ncols() {
                    meta_features[[i, n_base_models + j]] = x[[i, j]];
                }
            }
        }

        let meta_factory = self.meta_learner_factory.as_ref().unwrap();
        let meta_learner = meta_factory(&meta_features, y)?;

        self.fitted_base_models = Some(fitted_models);
        self.fitted_meta_learner = Some(meta_learner);

        Ok(())
    }

    /// Make predictions
    pub fn predict(&self, x: &Array2<f64>) -> Result<Array1<f64>> {
        let fitted_models = self.fitted_base_models.as_ref().ok_or_else(|| {
            KolosalError::ValidationError("Model not fitted".to_string())
        })?;

        let meta_learner = self.fitted_meta_learner.as_ref().ok_or_else(|| {
            KolosalError::ValidationError("Model not fitted".to_string())
        })?;

        let n_samples = x.nrows();
        let n_base_models = fitted_models.len();

        let meta_features_cols = if self.config.passthrough {
            n_base_models + x.ncols()
        } else {
            n_base_models
        };
        let mut meta_features = Array2::zeros((n_samples, meta_features_cols));

        for (base_idx, fold_models) in fitted_models.iter().enumerate() {
            let mut sum_preds = Array1::zeros(n_samples);
            
            for model in fold_models {
                let preds = model.predict(x)?;
                sum_preds = sum_preds + preds;
            }

            let avg_preds = sum_preds / fold_models.len() as f64;

            for i in 0..n_samples {
                meta_features[[i, base_idx]] = avg_preds[i];
            }
        }

        if self.config.passthrough {
            for i in 0..n_samples {
                for j in 0..x.ncols() {
                    meta_features[[i, n_base_models + j]] = x[[i, j]];
                }
            }
        }

        meta_learner.predict(&meta_features)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_stacking_config_default() {
        let config = StackingConfig::default();
        assert_eq!(config.n_folds, 5);
        assert!(!config.use_probabilities);
        assert!(!config.passthrough);
    }
}
